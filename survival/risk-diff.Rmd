---
title: "Bootstrap risk difference example"
author: 'Ann Von Holle'
date: "July 14, 2016"
bibliography: bib1.bib
output:
  html_document:
   toc: true
   toc_depth: 4 
   theme: united
   number_sections: true
---


```{r setup, echo=FALSE}
# see http://stackoverflow.com/questions/24585254/working-with-knitr-using-subdirectories
  library(knitr)
  opts_knit$set(root.dir=normalizePath('../'))
  #opts_chunk$set(fig.path = "../figures/", dev='pdf') # corrected path and added dev
```


```{r packages, echo=FALSE}
  ### Specify packages for R and seed

  library(survival)
  library(data.table) 
  library(boot)
  library(plyr)
  set.seed(123) # set seed so you get same results each time you run.
```

```{r, echo=FALSE}
saspath <- 'C:/Program Files/SASHome/SASFoundation/9.4/sas.exe'
sasopts <- "-nosplash -log 'c:\\temp' -ls 80 -ps 60  -nocenter -nodate" # see http://bit.ly/1QB4ZTb
```

# SAS code to generate risk difference at last observed time point with bootstrapped confidence intervals.

```{r s-read, engine='sas', engine.path=saspath, engine.opts=sasopts, results='markup', echo=TRUE, message=F, warning=FALSE, eval=T}

* Bootstrapping survival diffs at last time point;

* 1) make fake data;

/*Simulating outcomes: hospitalization for CVD, all cause-mortality*/
/* See Bender 2005 (doi: 10.1002/sim.2059) */

data fake;
	call streaminit(1234);
	shape1=1;
	do i = 1 to 100;
		exposure = (rand('NORMAL',0,1)>0); * make binary exposure;

		lp1 = log(0.5)*exposure;

		v = rand("uniform");
		t1 = (-log(v) / ( 0.011*exp(lp1)))**(1/shape1) ; 

		c=rand("exponential")*200;  *random drop out;
	
		t = min(t1,c);

		if t=t1 then delta=1;
		if t=c then delta=2;

	if t>10 then do; 
          t=10; delta=0; *admin censoring at 10 y; 
    end; 

	output;
	end;
run;

proc means data=fake; var exposure; run; * check;

ods select parameterestimates;
proc phreg data=fake;
	class exposure / desc;
 	 model t*delta(0,2) = exposure;
	 baseline out=surv1 survival=s;
run;

proc print data=surv1(obs=10); run;

* 2) Get observed statistic of interest;

data covs2;
input exposure;
datalines;
0
1
;
run;
proc print data=covs2; run;

ods select parameterestimates;
proc phreg data=fake;
	class exposure / desc;
	model t*delta(0,2) = exposure;
	baseline covariates=covs2 out=base survival=s stderr=se / method=pl; *output survival function and se;
run;

proc print data=base; run;

* Select last observation for each exposure to get comparison;

proc sort data=base; by exposure t; run;

data base2; set base;
	by exposure;
	if last.exposure;
	run;

proc print data=base2; run;

proc transpose data=base2 (keep=exposure s) out=base3; run;
data base3; set base3; if _n_=2;  diff = col1-col2; run; * risk diff for col2-col1;
proc print data=base3; run;

*store the estimated diff;
data _null_;
 set base3;
 if _n_=1 then  call symput('diffbar', diff);
run;

* 3) get bootstrap sample;
* SEE http://www.ats.ucla.edu/stat/sas/faq/bootstrap.htm;
* -------------------------------------------------------;

%let rep = 100;	
proc surveyselect data= fake out=bootsample
     seed = 124 method = urs
	 samprate = 1 outhits rep = &rep;
run;
ods listing close;

* 4) generate the data for diff in each bootstrap sample;
* -----------------------------------------------;

* get survival estimates for each replicate for each exposure;
proc phreg data=bootsample;
by replicate;
	class exposure / desc;
	model t*delta(0,2) = exposure;
	baseline covariates=covs2 out=base survival=s stderr=se / method=pl; *output survival function and se;
run;

proc freq data=base; table replicate; run; * check;

* pull out survival estimate for last time for each replicate;
proc sort data=base; by replicate exposure; run;
data base2; set base; 
by replicate exposure;
if last.exposure; 
run;

proc print data=base2(obs=20); run; * check;

* set up to get diff in S by exposure;
proc transpose data=base2 (keep=replicate exposure s) out=base3; by replicate; run;
data base3; set base3(where=(_name_='s')); diff=col1-col2; run;
proc print data=base3; run;


* 5) creating confidence interval, normal distribution theory method;
* using the t-distribution;
* -------------------------------------------;
%put &diffbar.;

%let alphalev = .05;
ods listing;
proc sql;
  select  &diffbar as diff,
          mean(diff) - &diffbar as bias, 
		  std(diff) as std_err,
          &diffbar - tinv(1-&alphalev/2, &rep-1)*std(diff) as lb,
          &diffbar + tinv(1-&alphalev/2, &rep-1)*std(diff) as hb
  from base3;
quit; 

```


# R version of SAS code above

## Generate data

```{r-gen}

  N=100
  shape.t1 = 1 # cvd event
  shape.t2 = 1 # all-cause mortality
  shape.c = 1 # censoring hazard, shape=1: exponential distribution
  
      exposure = ifelse(runif(N)>0.5,1,0) # binary exposure variable split evenly
      
      lp.1 = log(0.5)*exposure # linear predictor for proportional odds model
      
      # Weibull latent event times (really exponential)
      v <- runif(N)
      t.1 <- (- log(v) / (0.011 * exp(lp.1)))^(1 / shape.t1)
      
      # censoring times
      c = rexp(n=N, rate=1)*200
      
      # follow-up times and event indicators vectors
      t.orig = pmin(t.1,  c) # take min of time of 3 parallel        
      
      delta = ifelse(t.orig>10, 0,
                   ifelse(t.orig==t.1, 1,
                                 ifelse(t.orig==c, 2, NA))) # 0 and 2 are censored, 1 is event

      event = ifelse(delta %in% c(1), 1, 0)

      t = ifelse(t.orig>10, 10, t.orig) # administrative censoring at 10 years.
      
      delta.f = factor(delta, labels = c("admin censor", "event", "censor"))
      
      table(event)
      coef(coxph(Surv(t, event) ~ exposure)) # check
      
      fake.dat = data.frame(t = t, event=event, exposure=exposure)
```      
      
## Get observed risk from data

```{r getrisk}
      # get risk and time info from data
      
      dat1 = summary(survfit(Surv(t, event) ~ 1 + strata(exposure), data=fake.dat))
      dat2 = data.frame(
        strata = dat1$strata,
        t = dat1$time,
        n = dat1$n.risk,
        r = dat1$surv)
      head(dat2)
      
      # pick last risk estimate for each strata 
      dt2 = data.table(dat2)
      head(dt2)
      dt2[, .SD[c(.N)], by=strata]

      
      ddply(dat2, "strata", function(z) tail(z,1)) # different way to get last row by group

      
      # Get observed diff at last time point for each strata
      obs.diff = dt2$r[2] - dt2$r[1]; obs.diff
      
```


## Now boostrap data and get risk differences for each boostrap sample

```{r boot}

# Get bootstrap samples

# Function to obtain risk diff from the data
get.diff <- function(data, i) {
    d <- data[i,] # allows boot to select 

  dat1.pre = survfit(Surv(t, event) ~ 1 + strata(exposure), data=d)
  dat1 = summary(dat1.pre)
  
      dat2.1 = data.frame(
        strata = dat1$strata,
        t = dat1$time,
        n = dat1$n.risk,
        r = dat1$surv)
  
      # pick last risk estimate for each strata 
      dt2.1 = ddply(dat2.1, "strata", function(z) tail(z,1) )
      
#      dt2.1 = data.table(dat2.1)
#      dt2.1[, .SD[c(.N)], by=strata]

      # Get observed diff at last time point for each strata
      diff.1 = dt2.1$r[2] - dt2.1$r[1]

      return(diff.1)

} 

# bootstrapping with 100 replications (this is just an example and I want this to run quickly)
results <- boot(data=fake.dat, 
                statistic=get.diff,
                R=100)

results$t0 # the observed difference
mean(results$t, na.rm=T) - results$t0
sd(results$t, na.rm=T)

plot(results)
boot.ci(results, type="basic") # get bootstrapped confidence intervals

```